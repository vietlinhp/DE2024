{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"BasicDFOperationsApp\").master(\"spark://spark-master:7077\").getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark can infer the schema from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', LongType(), True)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"json\").load(\"/home/jovyan/data/2015-summary.json\")\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a schema explicitly and use it to load and validate the dataset. The recommendation is to use an explicit schema because schema inference can lead to precision issues (e.g., inferring Integer type as long type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "explicitSchema = StructType([\n",
    " StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    " StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    " StructField(\"count\", LongType(), False, metadata={\"somemetaname\":\"somemetavalue\"})\n",
    "])\n",
    "\n",
    "dfes = spark.read.format(\"json\").schema(explicitSchema)\\\n",
    "          .load(\"/home/jovyan/data/2015-summary.json\")\n",
    "dfes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a set of records from a data frame using column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "|    United States|            Ireland|\n",
      "+-----------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\")\n",
    "newdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use \"expr\" function as the parameters of \"select\". To further simplify, Spark provides a new function selectExpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|       target|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------------+\n",
      "|       target|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "# Both the following expressions are doing the same.\n",
    "df.select(expr(\"DEST_COUNTRY_NAME as target\")).show(2)\n",
    "\n",
    "df.selectExpr(\"DEST_COUNTRY_NAME as target\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+--------------------+-------------------+-----+-------------+\n",
      "|       United States|            Romania|   15|        false|\n",
      "|       United States|            Croatia|    1|        false|\n",
      "|       United States|            Ireland|  344|        false|\n",
      "|               Egypt|      United States|   15|        false|\n",
      "|       United States|              India|   62|        false|\n",
      "|       United States|          Singapore|    1|        false|\n",
      "|       United States|            Grenada|   62|        false|\n",
      "|          Costa Rica|      United States|  588|        false|\n",
      "|             Senegal|      United States|   40|        false|\n",
      "|             Moldova|      United States|    1|        false|\n",
      "|       United States|       Sint Maarten|  325|        false|\n",
      "|       United States|   Marshall Islands|   39|        false|\n",
      "|              Guyana|      United States|   64|        false|\n",
      "|               Malta|      United States|    1|        false|\n",
      "|            Anguilla|      United States|   41|        false|\n",
      "|             Bolivia|      United States|   30|        false|\n",
      "|       United States|           Paraguay|    6|        false|\n",
      "|             Algeria|      United States|    4|        false|\n",
      "|Turks and Caicos ...|      United States|  230|        false|\n",
      "|       United States|          Gibraltar|    1|        false|\n",
      "+--------------------+-------------------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column. Use a Boolean expression for generating values for the column \n",
    "df.selectExpr(\n",
    "    \"*\", # all original columns\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\\\n",
    ".show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add columns. lit function creates a Column of a literal value. Using Spark withColumn() function we can add , rename , derive, split, etc a Dataframe Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|OneConst|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "|    United States|            Romania|   15|       1|\n",
      "|    United States|            Croatia|    1|       1|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df.withColumn(\"OneConst\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rename columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"target\")\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also remove columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(\"ORIGIN_COUNTRY_NAME\")\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also cast data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('countlong', LongType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.withColumn(\"countlong\", col(\"count\").cast(\"long\")).drop(\"count\").schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the rows using the where function, similar to SQL where clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"count < 2\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a subset of data, similar to SQL SELECT statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\").count()\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a random sample from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can randomly split a dataset into multiple subsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 5\n",
    "weights = [0.25, 0.75]\n",
    "dataFrames = df.randomSplit(weights, seed)\n",
    "dataFrames[0].count() > dataFrames[1].count() # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can order or sort a dataset in ascending or descending order, similar to SQL Order By clause.\n",
    "Sort vs OrderBy https://towardsdatascience.com/sort-vs-orderby-in-spark-8a912475390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "|             Moldova|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|            Suriname|      United States|    1|\n",
      "|       United States|             Cyprus|    1|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "|            Djibouti|      United States|    1|\n",
      "|       United States|            Estonia|    1|\n",
      "|              Zambia|      United States|    1|\n",
      "|              Cyprus|      United States|    1|\n",
      "|       United States|          Lithuania|    1|\n",
      "|       United States|           Bulgaria|    1|\n",
      "|       United States|            Georgia|    1|\n",
      "|       United States|            Bahrain|    1|\n",
      "|       Cote d'Ivoire|      United States|    1|\n",
      "|       United States|   Papua New Guinea|    1|\n",
      "|              Kosovo|      United States|    1|\n",
      "|                Iraq|      United States|    1|\n",
      "|           Indonesia|      United States|    1|\n",
      "|       New Caledonia|      United States|    1|\n",
      "|       United States|         Montenegro|    1|\n",
      "|       United States|            Namibia|    1|\n",
      "|             Liberia|      United States|    2|\n",
      "|             Hungary|      United States|    2|\n",
      "|       United States|            Vietnam|    2|\n",
      "|            Malaysia|      United States|    2|\n",
      "|           Greenland|      United States|    2|\n",
      "|             Croatia|      United States|    2|\n",
      "|       United States|            Liberia|    2|\n",
      "|       United States|              Malta|    2|\n",
      "|             Georgia|      United States|    2|\n",
      "|               Niger|      United States|    2|\n",
      "|       United States|          Indonesia|    2|\n",
      "|       United States|           Malaysia|    3|\n",
      "|            Thailand|      United States|    3|\n",
      "|       United States|            Hungary|    3|\n",
      "|           Singapore|      United States|    3|\n",
      "|             Tunisia|      United States|    3|\n",
      "|    Papua New Guinea|      United States|    3|\n",
      "|            Bulgaria|      United States|    3|\n",
      "|       United States|           Thailand|    4|\n",
      "|             Algeria|      United States|    4|\n",
      "|       United States|          Greenland|    4|\n",
      "|       French Guiana|      United States|    5|\n",
      "|       United States|           Paraguay|    6|\n",
      "|            Pakistan|      United States|   12|\n",
      "|       United States|              Egypt|   12|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 50 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Moldova|      United States|    1|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, asc, col, expr\n",
    "\n",
    "df.sort(\"count\").show(50)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)\n",
    "df.orderBy(expr(\"count desc\")).show(2)\n",
    "df.orderBy(col(\"count\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can limit the size of a dataframe (result). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can collect the data to our driver program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Grenada', count=62),\n",
       " Row(DEST_COUNTRY_NAME='Costa Rica', ORIGIN_COUNTRY_NAME='United States', count=588),\n",
       " Row(DEST_COUNTRY_NAME='Senegal', ORIGIN_COUNTRY_NAME='United States', count=40),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF = df.limit(10)\n",
    "collectDF.take(5) # take works with an Integer count\n",
    "collectDF.show() # this prints it out nicely\n",
    "collectDF.show(5, False) # prints only 5. truncate=\n",
    "collectDF.collect() # gets all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the spark context\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
